# ğŸ“Š IPO Scraper Project Flow - Simple Explanation

## ğŸ”„ Complete Flow (Step by Step)

### **Step 1: User Makes Request** ğŸŒ
```
User â†’ GET /ipo/scrape?url=https://www.chittorgarh.com/ipo/...
```

### **Step 2: FastAPI Receives Request** ğŸšª
**File: `app/main.py`**
- FastAPI app starts
- Routes request to `/ipo/scrape` endpoint

### **Step 3: API Endpoint** ğŸ“¡
**File: `app/api/ipo.py`**
- Receives the URL from query parameter
- Calls `scrape_ipo(url)` function
- Returns the scraped data as JSON

### **Step 4: HTML Download/Save** ğŸ’¾
**File: `app/scraper/fetcher.py`**
- **Option A**: Downloads fresh HTML from the website using `requests`
- **Option B**: Uses previously saved HTML from `html_cache/` folder
- Saves HTML to: `html_cache/{external_id}.html`
- Saves metadata to: `html_cache/{external_id}.json`

### **Step 5: Parse HTML** ğŸ”
**File: `app/scraper/parser.py`**
- Uses BeautifulSoup to convert HTML into a searchable structure
- Provides helper functions to find data:
  - `get_value_by_label_contains()` - Find values in tables
  - `extract_list()` - Extract list items
  - `extract_section_by_heading()` - Get sections by heading
  - `extract_link_by_text()` - Find links
  - And many more...

### **Step 6: Extract Data** ğŸ“‹
**File: `app/scraper/chittorgarh.py`**
- Main function: `scrape_ipo()` orchestrates everything
- Internal function: `_scrape_ipo_from_soup()` does the actual extraction
- Extracts 50+ fields:
  - Basic info (name, ID, slug)
  - Issue details (size, price, dates)
  - Company info (website, sector, codes)
  - Lists (strengths, weaknesses, products, etc.)
  - URLs (DRHP, RHP, prospectus)
  - And more...

### **Step 7: Normalize Data** ğŸ”§
**File: `app/utils/normalizers.py`**
- Converts text to proper formats:
  - `parse_float()` - "â‚¹10 per share" â†’ 10.0
  - `parse_int()` - "120 Shares" â†’ 120
  - `parse_date()` - "Wed, Jan 28, 2026" â†’ 2026-01-28

### **Step 8: Return JSON Response** ğŸ“¤
- Data is validated against `app/schemas/ipo.py` (Pydantic model)
- Returns structured JSON to the user

---

## ğŸ¯ Visual Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER REQUEST                              â”‚
â”‚  GET /ipo/scrape?url=https://chittorgarh.com/ipo/2526/      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI App (app/main.py)                       â”‚
â”‚  - Receives HTTP request                                     â”‚
â”‚  - Routes to /ipo/scrape endpoint                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           API Endpoint (app/api/ipo.py)                     â”‚
â”‚  - Extracts URL from query parameter                        â”‚
â”‚  - Calls scrape_ipo(url)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        HTML Fetcher (app/scraper/fetcher.py)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Option A: Download Fresh                     â”‚          â”‚
â”‚  â”‚  - Uses requests library                    â”‚          â”‚
â”‚  â”‚  - Downloads HTML from website              â”‚          â”‚
â”‚  â”‚  - Saves to html_cache/{id}.html            â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Option B: Use Saved HTML                     â”‚          â”‚
â”‚  â”‚  - Loads from html_cache/{id}.html          â”‚          â”‚
â”‚  â”‚  - No network request needed                â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         HTML Parser (app/scraper/parser.py)                 â”‚
â”‚  - BeautifulSoup converts HTML to searchable structure      â”‚
â”‚  - Helper functions find specific data:                      â”‚
â”‚    â€¢ Tables, Lists, Sections, Links, etc.                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Data Extractor (app/scraper/chittorgarh.py)            â”‚
â”‚  - Extracts 50+ data fields:                                â”‚
â”‚    â€¢ Name, ID, Slug                                         â”‚
â”‚    â€¢ Issue Size, Price, Dates                               â”‚
â”‚    â€¢ Company Info, Sector                                   â”‚
â”‚    â€¢ Strengths, Weaknesses, Products                        â”‚
â”‚    â€¢ URLs, Codes, Ratings                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Data Normalizer (app/utils/normalizers.py)             â”‚
â”‚  - Converts text to proper formats:                         â”‚
â”‚    â€¢ "â‚¹10" â†’ 10.0 (float)                                   â”‚
â”‚    â€¢ "120 Shares" â†’ 120 (int)                               â”‚
â”‚    â€¢ "Jan 28, 2026" â†’ 2026-01-28 (date)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Schema Validation (app/schemas/ipo.py)              â”‚
â”‚  - Pydantic validates data structure                        â”‚
â”‚  - Ensures all fields match expected format                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    JSON RESPONSE                             â”‚
â”‚  Returns structured data to user                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ Key Concepts

### **1. HTML Caching** ğŸ’¾
- **Why?** Avoid re-downloading the same page
- **How?** Saves HTML to `html_cache/` folder
- **Benefit:** Faster parsing, works offline

### **2. Two-Stage Process** ğŸ”„
- **Stage 1**: Download & Save HTML (can be done separately)
- **Stage 2**: Parse saved HTML (can be done multiple times)

### **3. Modular Design** ğŸ§©
- **Fetcher**: Handles downloading/saving
- **Parser**: Handles HTML parsing
- **Scraper**: Orchestrates everything
- **Normalizers**: Clean and format data

---

## ğŸ“ Example: What Happens When You Call the API

**Request:**
```
GET /ipo/scrape?url=https://www.chittorgarh.com/ipo/shadowfax-technologies-ipo/2526/
```

**What Happens:**
1. âœ… API receives request
2. âœ… Downloads HTML (or uses saved version)
3. âœ… Saves HTML to `html_cache/2526.html`
4. âœ… Parses HTML with BeautifulSoup
5. âœ… Extracts all data fields
6. âœ… Normalizes values (dates, numbers, etc.)
7. âœ… Validates against schema
8. âœ… Returns JSON response

**Response:**
```json
{
  "external_id": 2526,
  "name": "Shadowfax Technologies IPO Details",
  "issue_size_crore": 153812096,
  "listing_date": "2026-01-28",
  ...
}
```

---

## ğŸ¯ Benefits of This Approach

1. **Efficient**: HTML saved once, parsed many times
2. **Reliable**: Works even if website is down (using saved HTML)
3. **Flexible**: Can parse from files directly
4. **Maintainable**: Each component has a single responsibility
5. **Testable**: Easy to test each part separately
